{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import model\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "reload(model)\n",
      "from sklearn import metrics\n",
      "from random import sample"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train, target, test, solution = model.data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# undersample training data\n",
      "# get the training set index\n",
      "def balance(n):\n",
      "    subscriber_index = target[target == 1].index\n",
      "    user_index = target[target == 0].index\n",
      "    # randomly select users\n",
      "    chosen = sample(list(user_index), len(subscriber_index)*n)\n",
      "    # create a new training set with equal parts subsriber and users\n",
      "    under_trained = train.ix[list(subscriber_index) + chosen]\n",
      "    under_target = target.ix[list(subscriber_index) + list(chosen)]\n",
      "    # sanity checky\n",
      "    print sum(under_trained.index != under_target.index)\n",
      "    return under_trained, under_target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# RF on undersampled data set\n",
      "# for i in range(5):\n",
      "#     under_trained, under_target = balance(i)\n",
      "#     mod, top_features = model.growforest(under_trained, under_target, 100)\n",
      "#     solutions3, predictions3, score3 = model.make_predictions(test, solution, model = mod)\n",
      "#     print score3\n",
      "#     print metrics.confusion_matrix(solution, predictions3)\n",
      "under_trained, under_target = balance(1)\n",
      "mod, top_features = model.growforest(under_trained, under_target, 100)\n",
      "solutions3, predictions3, score3 = model.make_predictions(test, solution, model = mod)\n",
      "print score3\n",
      "print metrics.confusion_matrix(solution, predictions3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "0.753854332802"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[2610  871]\n",
        " [  55  226]]\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Naive Bayes on undersampled data\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "nb = MultinomialNB()\n",
      "nb.fit(under_trained + -1*(np.min(np.array(under_trained))), under_target)\n",
      "preds = nb.predict(test)\n",
      "print nb.score(test, solution)\n",
      "print metrics.confusion_matrix(solution, preds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import OneClassSVM\n",
      "# one class svm only on samples that don't subscribe\n",
      "new_index = target[target == 0].index\n",
      "new_train = train.ix[new_index]\n",
      "#new_target = target.ix[new_index]\n",
      "#oneclass = OneClassSVM()\n",
      "#oneclass.fit(new_train)\n",
      "#predictions = oneclass.predict(test)\n",
      "fixed = []\n",
      "for pred in predictions:\n",
      "    if pred == -1:\n",
      "        fixed.append(0)\n",
      "    else:\n",
      "        fixed.append(int(pred))\n",
      "fixed = pd.Series(fixed)\n",
      "print metrics.confusion_matrix(solution, fixed)\n",
      "print sum(fixed == solution)*1.0/len(solution)\n",
      "# pretty terrible"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[1714 1767]\n",
        " [ 117  164]]\n",
        "0.499202551834\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.decomposition import ProbabilisticPCA\n",
      "# pca = ProbabilisticPCA(n_components='mle')\n",
      "# fitted = pca.fit_transform(train)\n",
      "pca_test = pca.transform(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "<module 'model' from 'model.py'>"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target.index = range(len(target.index))\n",
      "pca_rebalanced, balanced_target = model.balance(10, pd.DataFrame(fitted), target)\n",
      "one_train = fitted[target == 0]\n",
      "print pca_rebalanced.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sanity check 0\n",
        "(7623, 1152)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import OneClassSVM\n",
      "sv = OneClassSVM()\n",
      "sv.fit(one_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 135,
       "text": [
        "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.0, kernel='rbf',\n",
        "      max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
        "      verbose=False)"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "one_class_solutions = [i if i == 1.0 else -1 for i in solution]\n",
      "#one_class_preds = sv.predict(pca_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metrics.confusion_matrix(one_class_solutions, one_class_preds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 148,
       "text": [
        "array([[1711, 1770],\n",
        "       [ 116,  165]])"
       ]
      }
     ],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "preds = sv.predict(pca_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum(preds == -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "1827"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.svm import SVC\n",
      "x = 8\n",
      "recall_df = pd.DataFrame(index = range(x), columns = ['logreg','rfmod','sv'])\n",
      "for i in range(8):\n",
      "    i += 1\n",
      "    pca_rebalanced, balanced_target = model.balance(i, pd.DataFrame(fitted), target)\n",
      "    one_train = fitted[target == 0]\n",
      "    logreg = LogisticRegression()\n",
      "    rfmod = RandomForestClassifier()\n",
      "    nb = MultinomialNB()\n",
      "    sv = SVC()\n",
      "    \n",
      "    rfmod.fit(pca_rebalanced, balanced_target)\n",
      "    logreg.fit(pca_rebalanced, balanced_target)\n",
      "    #nb.fit(pca_rebalanced, balanced_target)\n",
      "    sv.fit(pca_rebalanced, balanced_target)\n",
      "    \n",
      "    preds1 = logreg.predict(pca_test)\n",
      "    preds2 = rfmod.predict(pca_test)\n",
      "    #preds3 = nb.predict(pca_test)\n",
      "    preds4 = sv.predict(pca_test)\n",
      "    \n",
      "    recall_df['logreg'][i-1] = metrics.recall_score(solution, preds1)\n",
      "    recall_df['rfmod'][i-1] = metrics.recall_score(solution, preds2)\n",
      "    #recall_df['nb'][i-1] = metrics.recall_score(solution, preds3)\n",
      "    recall_df['sv'][i-1] = metrics.recall_score(solution, preds4)\n",
      "    #print metrics.precision_score(solution, preds)\n",
      "    #print metrics.recall_score(solution, preds)\n",
      "#     print '***** logreg at iteration {!s} ****'.format(i)\n",
      "#     #print metrics.f1_score(solution, preds1)\n",
      "#     print metrics.recall_score(solution, preds1)\n",
      "#     print metrics.confusion_matrix(solution, preds1)\n",
      "#     print sum(preds1 == solution)*1.0/len(preds1)\n",
      "#     print '***** rf at iteration {!s} ****'.format(i)\n",
      "#     print metrics.f1_score(solution, preds2)\n",
      "#     print metrics.confusion_matrix(solution, preds2)\n",
      "#     print sum(preds2 == solution)*1.0/len(preds2)\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sanity check 0\n",
        "***** logreg at iteration 1 ****"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.79359430605\n",
        "[[2440 1041]\n",
        " [  58  223]]\n",
        "0.707868155237\n",
        "***** rf at iteration 1 ****\n",
        "0.307060755337\n",
        "[[2731  750]\n",
        " [  94  187]]\n",
        "0.775651249335"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sanity check 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "***** logreg at iteration 2 ****"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.693950177936\n",
        "[[2797  684]\n",
        " [  86  195]]\n",
        "0.795321637427\n",
        "***** rf at iteration 2 ****\n",
        "0.345177664975\n",
        "[[3110  371]\n",
        " [ 145  136]]\n",
        "0.86283891547\n",
        "sanity check 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "***** logreg at iteration 3 ****"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.576512455516\n",
        "[[3014  467]\n",
        " [ 119  162]]\n",
        "0.8442317916\n",
        "***** rf at iteration 3 ****\n",
        "0.351046698873\n",
        "[[3250  231]\n",
        " [ 172  109]]\n",
        "0.892876129718\n",
        "sanity check 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "***** logreg at iteration 4 ****"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.483985765125\n",
        "[[3135  346]\n",
        " [ 145  136]]\n",
        "0.869484316853\n",
        "***** rf at iteration 4 ****\n",
        "0.308550185874\n",
        "[[3307  174]\n",
        " [ 198   83]]\n",
        "0.901116427432\n",
        "sanity check 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "***** logreg at iteration 5 ****"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.448398576512\n",
        "[[3237  244]\n",
        " [ 155  126]]\n",
        "0.893939393939\n",
        "***** rf at iteration 5 ****\n",
        "0.289915966387\n",
        "[[3355  126]\n",
        " [ 212   69]]\n",
        "0.910154173312\n",
        "sanity check 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "***** logreg at iteration 6 ****"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.402135231317\n",
        "[[3264  217]\n",
        " [ 168  113]]\n",
        "0.897660818713\n",
        "***** rf at iteration 6 ****\n",
        "0.261682242991\n",
        "[[3390   91]\n",
        " [ 225   56]]\n",
        "0.916002126528\n",
        "sanity check 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "***** logreg at iteration 7 ****"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.366548042705\n",
        "[[3314  167]\n",
        " [ 178  103]]\n",
        "0.908293460925\n",
        "***** rf at iteration 7 ****\n",
        "0.249363867684\n",
        "[[3418   63]\n",
        " [ 232   49]]\n",
        "0.92158426369\n",
        "sanity check 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/paul/anaconda/python.app/Contents/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1809: UserWarning: The precision and recall are equal to zero for some labels. fbeta_score is ill defined for those labels [ 1.]. \n",
        "  average=average)\n",
        "/Users/paul/anaconda/python.app/Contents/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1809: UserWarning: The sum of true positives and false positives are equal to zero for some labels. Precision is ill defined for those labels [ 1.]. The precision and recall are equal to zero for some labels. fbeta_score is ill defined for those labels [ 1.]. \n",
        "  average=average)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "***** logreg at iteration 8 ****"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.302491103203\n",
        "[[3333  148]\n",
        " [ 196   85]]\n",
        "0.90855927698\n",
        "***** rf at iteration 8 ****\n",
        "0.208791208791\n",
        "[[3436   45]\n",
        " [ 243   38]]\n",
        "0.923444976077\n"
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "recall_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/paul/anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/core/config.py:570: DeprecationWarning: height has been deprecated.\n",
        "\n",
        "  warnings.warn(d.msg, DeprecationWarning)\n",
        "/Users/paul/anaconda/python.app/Contents/lib/python2.7/site-packages/pandas/core/config.py:570: DeprecationWarning: height has been deprecated.\n",
        "\n",
        "  warnings.warn(d.msg, DeprecationWarning)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>logreg</th>\n",
        "      <th>rfmod</th>\n",
        "      <th>sv</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0.7935943</td>\n",
        "      <td> 0.6654804</td>\n",
        "      <td>   0.7580071</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0.6939502</td>\n",
        "      <td> 0.4839858</td>\n",
        "      <td>   0.4946619</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0.5765125</td>\n",
        "      <td> 0.3879004</td>\n",
        "      <td>   0.2348754</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0.4839858</td>\n",
        "      <td> 0.2953737</td>\n",
        "      <td>   0.1423488</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0.4483986</td>\n",
        "      <td> 0.2455516</td>\n",
        "      <td>   0.0569395</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> 0.4021352</td>\n",
        "      <td> 0.1992883</td>\n",
        "      <td> 0.003558719</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>  0.366548</td>\n",
        "      <td> 0.1743772</td>\n",
        "      <td>           0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> 0.3024911</td>\n",
        "      <td> 0.1352313</td>\n",
        "      <td>           0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 132,
       "text": [
        "      logreg      rfmod           sv\n",
        "0  0.7935943  0.6654804    0.7580071\n",
        "1  0.6939502  0.4839858    0.4946619\n",
        "2  0.5765125  0.3879004    0.2348754\n",
        "3  0.4839858  0.2953737    0.1423488\n",
        "4  0.4483986  0.2455516    0.0569395\n",
        "5  0.4021352  0.1992883  0.003558719\n",
        "6   0.366548  0.1743772            0\n",
        "7  0.3024911  0.1352313            0"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metrics.precision_recall_curve(solution, logreg.predict_proba(pca_test)[:,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 113,
       "text": [
        "(array([ 0.0770074 ,  0.07675439,  0.07677543, ...,  0.        ,\n",
        "        0.        ,  1.        ]),\n",
        " array([ 1.        ,  0.99644128,  0.99644128, ...,  0.        ,\n",
        "        0.        ,  0.        ]),\n",
        " array([  2.37140406e-07,   2.63682378e-07,   2.89019686e-07, ...,\n",
        "         1.00000000e+00,   1.00000000e+00,   1.00000000e+00]))"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metrics.auc("
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(pca, file('skpca.pkl', 'w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}